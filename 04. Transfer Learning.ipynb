{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "730524e9",
   "metadata": {},
   "source": [
    "# 1. Transfer learning (story - aila)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "2ad47995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating story pairs\n",
    "\n",
    "import pandas \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pandas.read_csv(\"C:/Users/Thiloshon/PycharmProjects/analogical-transfer-learning/02_aesop_fables_annotated.csv\")\n",
    "stories = list(data['story'])\n",
    "tags = list(data['tag'])\n",
    "\n",
    "pairs = []\n",
    "unpairs = []\n",
    "\n",
    "for l1 in range(0, len(stories)):\n",
    "    for l2 in range(l1, len(stories)):\n",
    "        if l1 != l2 and tags[l1]==tags[l2]:\n",
    "            pairs.append((stories[l1], stories[l2], 1))\n",
    "        elif l1 != l2 and tags[l1]!=tags[l2]:\n",
    "            unpairs.append((stories[l1], stories[l2], 0))\n",
    "            \n",
    "            \n",
    "import random\n",
    "\n",
    "random.shuffle(unpairs)\n",
    "random.shuffle(pairs)\n",
    "\n",
    "tot_pairs = pairs[0:544] + unpairs[0:544]\n",
    "train, dev = train_test_split(tot_pairs, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1e0a4825",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "2083d4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "870"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "31998f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a3f60d297a4abea098626ce3bb2a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79c4f78909c448a963b3af81245e030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b6755967e34cd397a9d77fd9bad603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea3be7360bc44a9921ad2da5eb57796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b6c3ef4bf54a86a09b52f7fae55a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251f54d1258849e8875140a82e7f5bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Learning\n",
    "from sentence_transformers import InputExample\n",
    "from sentence_transformers import models, losses, datasets\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from sentence_transformers.cross_encoder.evaluation import CEBinaryAccuracyEvaluator\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import CrossEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_samples = [InputExample(texts=[a[0], a[1]], label=int(a[2])) for a in train] \n",
    "\n",
    "model = CrossEncoder('distilroberta-base', num_labels=1)\n",
    "\n",
    "train_dataloader = datasets.NoDuplicatesDataLoader(train_samples, batch_size=32)\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)\n",
    "\n",
    "history = model.fit(train_dataloader  = train_dataloader,\n",
    "                    epochs=num_epochs,\n",
    "                    evaluation_steps=int(len(train_dataloader)*0.1),\n",
    "                    warmup_steps=warmup_steps,\n",
    "                    use_amp=False,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32d378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional training\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "history = model.fit(train_dataloader  = train_dataloader,\n",
    "                    epochs=num_epochs,\n",
    "                    evaluation_steps=int(len(train_dataloader)*0.1),\n",
    "                    warmup_steps=warmup_steps,\n",
    "                    use_amp=False,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "5bf424b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3804929 , 0.44115415, 0.5037675 , 0.5032178 , 0.46191627,\n",
       "       0.5032922 , 0.5777111 , 0.5014547 , 0.6060726 , 0.4776313 ,\n",
       "       0.44060907, 0.51764613, 0.45569417, 0.48611835, 0.49182463,\n",
       "       0.49153817, 0.5119049 , 0.47792956, 0.511141  , 0.44472578,\n",
       "       0.54157466, 0.4522344 , 0.52562857, 0.42123574, 0.38834342,\n",
       "       0.47088927, 0.44302174, 0.46462482, 0.4734608 , 0.51279604,\n",
       "       0.4453686 , 0.45378688, 0.44707826, 0.42289713, 0.44101983,\n",
       "       0.4464787 , 0.37810248, 0.53672385, 0.51047903, 0.44783714,\n",
       "       0.55179536, 0.4779942 , 0.4593432 , 0.48879158, 0.43366158,\n",
       "       0.48341691, 0.47425634, 0.38674322, 0.53586817, 0.5514141 ,\n",
       "       0.35558027, 0.49307546, 0.5607087 , 0.49468017, 0.42203146,\n",
       "       0.4581029 , 0.5025715 , 0.51077646, 0.4362424 , 0.3333053 ,\n",
       "       0.39356205, 0.52067477, 0.5091464 , 0.4563414 , 0.50054955,\n",
       "       0.42373574, 0.4401554 , 0.41290957, 0.4447588 , 0.47554126,\n",
       "       0.3686713 , 0.48349014, 0.44331217, 0.4914554 , 0.47157255,\n",
       "       0.4466226 , 0.45982215, 0.48646092, 0.40738153, 0.4500501 ,\n",
       "       0.5074313 , 0.5293153 , 0.46327338, 0.39481443, 0.40811327,\n",
       "       0.4990241 , 0.4586792 , 0.43430442, 0.47246695, 0.45449418,\n",
       "       0.43367323, 0.49720654, 0.38733575, 0.5042416 , 0.35573897,\n",
       "       0.43655428, 0.56915253, 0.46073335, 0.49694425, 0.44206372,\n",
       "       0.51446164, 0.48955035, 0.50574064, 0.38374665, 0.41775945,\n",
       "       0.4204121 , 0.50016266, 0.4921956 , 0.53014016, 0.49297392,\n",
       "       0.5170907 , 0.48110542, 0.5224333 , 0.47403854, 0.5097909 ,\n",
       "       0.51746196, 0.48116353, 0.44281563, 0.47266832, 0.44272146,\n",
       "       0.521015  , 0.43312874, 0.4779715 , 0.45421067, 0.56784415,\n",
       "       0.44039297, 0.42520827, 0.47117984, 0.49048018, 0.48077017,\n",
       "       0.5241131 , 0.45591488, 0.5571199 , 0.52890956, 0.44894907,\n",
       "       0.49605373, 0.40007836, 0.48684478, 0.4636668 , 0.4499017 ,\n",
       "       0.44701713, 0.40663394, 0.44350284, 0.4756792 , 0.512883  ,\n",
       "       0.52159226, 0.48387232, 0.40677947, 0.4181043 , 0.51074266,\n",
       "       0.5102766 , 0.5043464 , 0.49727938, 0.54567355, 0.5009599 ,\n",
       "       0.38993502, 0.52136123, 0.5665435 , 0.45597258, 0.50731224,\n",
       "       0.521802  , 0.52771044, 0.4217047 , 0.4634671 , 0.56589854,\n",
       "       0.4241887 , 0.42430708, 0.53179336, 0.45457265, 0.44512072,\n",
       "       0.4797103 , 0.46234003, 0.43166944, 0.52865607, 0.46238652,\n",
       "       0.461842  , 0.4821591 , 0.48074788, 0.52487403, 0.42183778,\n",
       "       0.4795052 , 0.40412164, 0.40179783, 0.4854978 , 0.48652402,\n",
       "       0.45903322, 0.43492576, 0.449411  , 0.48227742, 0.49642926,\n",
       "       0.5052368 , 0.48290408, 0.43787304, 0.4753207 , 0.47547862,\n",
       "       0.49120083, 0.43251494, 0.5277419 , 0.49381208, 0.40891334,\n",
       "       0.50544673, 0.4573455 , 0.49659806, 0.5124805 , 0.4446709 ,\n",
       "       0.5120815 , 0.5262237 , 0.40450296, 0.4895552 , 0.5108535 ,\n",
       "       0.52080727, 0.550334  , 0.4670286 , 0.5542291 , 0.48183113,\n",
       "       0.5262162 , 0.43192148, 0.38700497], dtype=float32)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_x = [(a[0], a[1]) for a in dev]\n",
    "dev_y = [a[2] for a in dev]\n",
    "a = model.predict(dev_x)\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3e62f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "threshold = 0.49\n",
    "\n",
    "preds = [int(ass > threshold) for ass in a]\n",
    "print(accuracy_score(dev_y, preds))\n",
    "print(f1_score(dev_y, preds, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "72a17f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transfer EVALUATION on analogy type #####\n",
    "\n",
    "\n",
    "test_data = pandas.read_csv(\"C:/Users/Thiloshon/PycharmProjects/analogical-transfer-learning/aesop_morals_pairs.csv\")[0:44]\n",
    "\n",
    "test_x = list(zip(list(test_data[\"STORY 1\"]), list(test_data[\"STORY 2\"])))\n",
    "\n",
    "test_pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f7534da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "# oo = \"SAA Score\tDAA Score\tRA Score\tSA Score\tMP Score\tLS Score\"\n",
    "\n",
    "test_y = list(test_data[\"LS Score\"])\n",
    "\n",
    "preds2 = [int(ass > threshold) for ass in test_pred]\n",
    "print(accuracy_score(test_y, preds2))\n",
    "print(f1_score(test_y, preds2, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5e476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transfer EVALUATION on AILA data #####\n",
    "\n",
    "# pair creation\n",
    "\n",
    "file1 = open('C:/Users/Thiloshon/PycharmProjects/analogical-transfer-learning/AILA_2019_dataset/relevance_judgments_priorcases.txt', 'r')\n",
    "lines = file1.readlines()\n",
    "\n",
    "m = [a.replace(\"\\n\", \"\").split(\" \") for a in lines]\n",
    "\n",
    "cases = {}\n",
    "\n",
    "for li in m:\n",
    "    if li[3] == \"1\":\n",
    "        gg = cases.get(li[0], [])\n",
    "        gg.append(li[2])\n",
    "        cases[li[0]] = gg\n",
    "\n",
    "un_cases = {}\n",
    "\n",
    "for li in m:\n",
    "    if li[3] == \"0\":\n",
    "        gg = un_cases.get(li[0], [])\n",
    "        gg.append(li[2])\n",
    "        un_cases[li[0]] = gg\n",
    "\n",
    "        \n",
    "pairs_1 = []\n",
    "\n",
    "for a in cases:\n",
    "    cs = cases[a]\n",
    "    \n",
    "    for l1 in range(0, len(cs)):\n",
    "        for l2 in range(l1, len(cs)):\n",
    "            if l1 != l2:\n",
    "                data1 = \"\"\n",
    "                data2 = \"\"\n",
    "                with open('AILA_2019_dataset/Object_casedocs/' + cs[l1] + \".txt\", 'r') as file:\n",
    "                    data1 = file.read().replace('\\n', '')[500: 2500] + cs[l1]\n",
    "                with open('AILA_2019_dataset/Object_casedocs/' + cs[l2] + \".txt\", 'r') as file:\n",
    "                    data2 = file.read().replace('\\n', '')[500: 2500] + cs[l2]\n",
    "                pairs_1.append((data1, data2, 1))\n",
    "                \n",
    "un_pairs_1 = []\n",
    "\n",
    "for a in un_cases:\n",
    "    cs = un_cases[a][0:6]\n",
    "    \n",
    "    for l1 in range(0, len(cs)):\n",
    "        for l2 in range(l1, len(cs)):\n",
    "            \n",
    "            if l1 != l2:\n",
    "                datas1 = \"\"\n",
    "                datas2 = \"\"\n",
    "                with open('AILA_2019_dataset/Object_casedocs/' + cs[l1] + \".txt\", 'r') as file:\n",
    "                    datas1 = file.read().replace('\\n', '')[500: 2500] + cs[l1]\n",
    "                with open('AILA_2019_dataset/Object_casedocs/' + cs[l2] + \".txt\", 'r') as file:\n",
    "                    datas2 = file.read().replace('\\n', '')[500: 2500] + cs[l2]\n",
    "                    \n",
    "                un_pairs_1.append((datas1, datas2, 0))\n",
    "    \n",
    "un_pairs_1 = un_pairs_1[0:640]\n",
    "tot_pair_1 = pairs_1 + un_pairs_1\n",
    "len(tot_pair_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ca70c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predition\n",
    "\n",
    "test_x = [(a[0], a[1]) for a in tot_pair_1]\n",
    "test_y = [a[2] for a in tot_pair_1]\n",
    "         \n",
    "a2 = model.predict(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874a0c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [int(ass > 0.45) for ass in a2]\n",
    "print(accuracy_score(test_y, preds))\n",
    "print(f1_score(test_y, preds, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17a36ea",
   "metadata": {},
   "source": [
    "# Transfer learning AILA - story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd2f276c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case pairs creation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas\n",
    "import random\n",
    "\n",
    "file1 = open('C:/Users/Thiloshon/PycharmProjects/analogical-transfer-learning/AILA_2019_dataset/relevance_judgments_priorcases.txt', 'r')\n",
    "lines = file1.readlines()\n",
    "\n",
    "m = [a.replace(\"\\n\", \"\").split(\" \") for a in lines]\n",
    "\n",
    "cases = {}\n",
    "\n",
    "for li in m:\n",
    "    if li[3] == \"1\":\n",
    "        gg = cases.get(li[0], [])\n",
    "        gg.append(li[2])\n",
    "        cases[li[0]] = gg\n",
    "\n",
    "un_cases = {}\n",
    "\n",
    "for li in m:\n",
    "    if li[3] == \"0\":\n",
    "        gg = un_cases.get(li[0], [])\n",
    "        gg.append(li[2])\n",
    "        un_cases[li[0]] = gg\n",
    "\n",
    "        \n",
    "pairs_1 = []\n",
    "\n",
    "for a in cases:\n",
    "    cs = cases[a]\n",
    "    \n",
    "    for l1 in range(0, len(cs)):\n",
    "        for l2 in range(l1, len(cs)):\n",
    "            if l1 != l2:\n",
    "                data1 = \"\"\n",
    "                data2 = \"\"\n",
    "                with open('AILA_2019_dataset/Object_casedocs/' + cs[l1] + \".txt\", 'r') as file:\n",
    "                    data1 = file.read().replace('\\n', '')[500: 2500] + cs[l1]\n",
    "                with open('AILA_2019_dataset/Object_casedocs/' + cs[l2] + \".txt\", 'r') as file:\n",
    "                    data2 = file.read().replace('\\n', '')[500: 2500] + cs[l2]\n",
    "                pairs_1.append((data1, data2, 1))\n",
    "                \n",
    "un_pairs_1 = []\n",
    "\n",
    "for a in un_cases:\n",
    "    cs = un_cases[a][0:6]\n",
    "    \n",
    "    for l1 in range(0, len(cs)):\n",
    "        for l2 in range(l1, len(cs)):\n",
    "            \n",
    "            if l1 != l2:\n",
    "                datas1 = \"\"\n",
    "                datas2 = \"\"\n",
    "                with open('AILA_2019_dataset/Object_casedocs/' + cs[l1] + \".txt\", 'r') as file:\n",
    "                    datas1 = file.read().replace('\\n', '')[500: 2500] + cs[l1]\n",
    "                with open('AILA_2019_dataset/Object_casedocs/' + cs[l2] + \".txt\", 'r') as file:\n",
    "                    datas2 = file.read().replace('\\n', '')[500: 2500] + cs[l2]\n",
    "                    \n",
    "                un_pairs_1.append((datas1, datas2, 0))\n",
    "print(len(un_pairs_1))\n",
    "    \n",
    "un_pairs_1 = un_pairs_1[0:640]\n",
    "\n",
    "tot_pair_1 = pairs_1 + un_pairs_1\n",
    "\n",
    "train, dev = train_test_split(tot_pair_1, test_size=0.20)\n",
    "random.shuffle(tot_pair_1)\n",
    "\n",
    "len(tot_pair_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3e0a866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0689202d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cec8de284284b32bf5b25e63d316460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6d26bde903499980c19294e9b5f111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/86.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/paraphrase-MiniLM-L6-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5280354285534fa5bf5132897dcbebeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc8693ad364481793b38c142d10f4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b2ef28c2644d45a96b1b69416583eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09562f4f9654ee6b583a56333c538d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f3513970e346be80543d05772c25dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eda423ffdd740d983c8f6f35966917d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Leanring similar cases\n",
    "\n",
    "from sentence_transformers import InputExample\n",
    "from sentence_transformers import models, losses, datasets\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from sentence_transformers.cross_encoder.evaluation import CEBinaryAccuracyEvaluator\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import CrossEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_samples = [InputExample(texts=[a[0], a[1]], label=int(a[2])) for a in train] \n",
    "\n",
    "model = CrossEncoder('sentence-transformers/paraphrase-MiniLM-L6-v2', num_labels=1)\n",
    "\n",
    "train_dataloader = datasets.NoDuplicatesDataLoader(train_samples, batch_size=32)\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)\n",
    "\n",
    "history = model.fit(train_dataloader  = train_dataloader,\n",
    "                    epochs=num_epochs,\n",
    "                    evaluation_steps=int(len(train_dataloader)*0.1),\n",
    "                    warmup_steps=warmup_steps,\n",
    "                    use_amp=False,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "25b47c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed93681512df454abd492a479e334a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78419567b44e445cb30608a3c02880cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(train_dataloader  = train_dataloader,\n",
    "                    epochs=num_epochs,\n",
    "                    evaluation_steps=int(len(train_dataloader)*0.1),\n",
    "                    warmup_steps=warmup_steps,\n",
    "                    use_amp=False,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "52a4fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev data evalatuion\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "dev_x = [(a[0], a[1]) for a in dev]\n",
    "dev_y = [a[2] for a in dev]\n",
    "a = model.predict(dev_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "52fb341c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73828125\n",
      "0.7332960146786709\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.453\n",
    "\n",
    "preds = [int(ass > threshold) for ass in a]\n",
    "print(accuracy_score(dev_y, preds))\n",
    "print(f1_score(dev_y, preds, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3dcd23f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transfer learning evaluation\n",
    "\n",
    "test_data = pandas.read_csv(\"C:/Users/Thiloshon/PycharmProjects/analogical-transfer-learning/aesop_morals_pairs.csv\")[0:44]\n",
    "\n",
    "test_x = list(zip(list(test_data[\"STORY 1\"]), list(test_data[\"STORY 2\"])))\n",
    "\n",
    "test_pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "641715cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "# oo = \"SAA Score\tDAA Score\tRA Score\tSA Score\tMP Score\tLS Score\"\n",
    "\n",
    "test_y = list(test_data[\"LS Score\"])\n",
    "\n",
    "preds2 = [int(ass > threshold) for ass in test_pred]\n",
    "print(accuracy_score(test_y, preds2))\n",
    "print(f1_score(test_y, preds2, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b67667e",
   "metadata": {},
   "source": [
    "# Annotation IAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8b0f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "\n",
    "data = pandas.read_csv(\"aesop_morals_com_JUMBLED_v4_stats.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a8b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_kappa_score(list(data[\"LS_SHON\"]), list(data[\"MP_F\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa246596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "\n",
    "from statsmodels.stats import inter_rater as irr\n",
    "\n",
    "\n",
    "agg = irr.aggregate_raters(data[[\"LS_JAY\", \"LS_SHON\", \"LS_F\"]]) # returns a tuple (data, categories)\n",
    "irr.fleiss_kappa(agg[0], method='fleiss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ytkern",
   "language": "python",
   "name": "ytkern"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
